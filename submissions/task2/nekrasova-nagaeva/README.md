# Постановка задачи

*Считать данные из training.csv. Проверить является ли ряд стационарным в широком смысле: провести визуальную оценку или провести тест Дики - Фуллера. Оценить достоверность статистики.  
Разложить временной ряд на тренд, сезональность. Проверить является ли временной ряд интегрированным порядка k. Применить к нему модель ARIMA, подобрав необходимые параметры. Предсказать значения для тестовой выборки. Визуализировать их, посчитать r2 score для каждой из моделей. Произвести отбор наилучшей модели с помощью информационного критерия Акаике.*

Временной ряд - совокупность наблюдений экономической величины в различные моменты времени.  
В нашем случае это последовательность случайных величин Value(t), где t ∈ \[01.01.1959, 01.12.1988\], Δt - месяц.  
Стохастический процесс - бесконечная последовательность {X(t), t = 0, ±1, ±2, ...}. 
Временной ряд - это реализация некоторого стохастического процесса.

Рассмотрим случайный процесс X(w,t), где w - случай, t - время.  
Его статистической характеристикой является совокупность совместных функций распределения:  
{ f1( x(t1) ), f2( x(t1), x(t2) ), f3( x(t1), x(t2), x(t3) ), ...}  

Временной ряд называется строго стационарным (стационарным в узком смысле), если сдвиг во времени не меняет 
ни одну из функций распределения. Получается, что при каждом фиксированном моменте времени случайный процесс есть
случайная величина, и для каждой из них можно рассматривать E[X], Var[X], ... .  
(Подразумевается сходимость данных рядов)

Cov(X(t1), X(t2)) =  ∫ ∫ (x(t1) - EX) \* (x(t2) - EX) \* f2(x(t1), x(t2))dx(t1)dx(t2)  
Заменим разность (t1 - t2) на  τ. Совокупность значений ковариаций при всевозможных значениях между моментами 
времени называется автоковариационной функцией случайного процесса -  γ.  
Коэффициент корреляции ρ(τ) =  γ(τ) /  γ(0). Автокорреляционная функция показывает,
насколько статистически зависимы значения временного ряда при различных сдвигах времени.
В нашем случае - за месяц, за два месяца и т.д.

Если случайный процесс таков, что у него мат. ожидание и дисперсия существуют и не зависят от времени, а γ и ρ зависят только от τ, то такой процесс является стационарным в широком смысле. Всякий стационарный в узком
смысле процесс стационарен в широком смысле. Обратное, вообще говоря, неверно.

Декомпозиция Вольда:  
Чисто недетерминированный стационарный в широком смысле случайный процесс X(t) может быть представлен  в виде
X(t) - E\[X(t)\] = ∑ ψ(t) \* ε(t - τ), t = \[0, ∞)  
где ε(j) - белый шум с конечными мат. ожиданием и дисперсией.  
То есть всякий стационарный процесс в общеем смысле представляется в виде линейной комбинации белых шумов
с разными весовыми коэффициентами.

Оператор сдвига ℒ: ℒX(t) = X(t-1);  
(ℒ^p)X(t) = ℒ(ℒ(ℒ...)X(t) = X(t-p), (ℒ^0)X(t) = X(t).

Если значение случайного процесса определяется линейной комбинацией конечного числа его предыдущих значений и добавлением белого шума, то такой процесс называется процессом авторегрессии порядка p и его общее уравнение имеет вид  
X(t) = α1\*X(t-1) + α2\*X(t-2) + ... + αp\*X(t-p) + εi, где εi - белый шум.

Стохастический процесс называется процессом скользящего среднего порядка q, если в разложении Вольда
присутствуют только q первых слагаемых. Название "скользящее среднее" объяснено тем, что текущее значение случайного процесса определяется взвешенным средним q предыдущих значений белого шума. - MA(q)

MA(q) :  
X(t) = ∑ β(τ) * ε(t-τ),  τ = \[0, q]   
X(t) = ( 1 + β1ℒ + ... + βq(ℒ^q) ) \* ε(t) = βq(ℒ)(t)
X(t) = βq ∏ (ℒ - Zi), i = \[1, q],     
где Zi - корни уравнения 1 + β1Z + ... + βq(Z^q) = 0


Процесс, обратный к MA(q) обозначается AR(∞). Если процесс AR стационарен, то он кроме конечного представления AR(p) имеет и бесконечное представление MA(∞). И если выполнено условие обратимости, то конечный процесс MA(q) имеет бесконечное представление AR(∞).

Частная автокорреляционная функция ρ(τ) = 1/(Var\[X(t)])  \*  E\[ (X(t) - EX)(X(t-τ) - EX) \]  
Она показывает коэффициент корреляции между X(t-k) и X(t) за вычетом той части x(t), которая линейно объяснена промежуточными лагами x(t-1), x(t-2), ... , x(t-k-1).  
Лаг - момент времени один шаг назад.  
PACF ρ(k) авторегрессионного процeсса AR(p) равна 0 для k>p.

Процесс авторегрессии скользящего среднего ARMA:  
X(t) = α1\*X(t-1) + ... + αp\*X(t-p) + ε(t) + β1\*ε(t-1) + ... + βq\*ε(t-q)

Если ряд после взятия d последовательных разностей приводится к стационарному, то он интегрированный порядка d.

Подход Бокса-Дженкинса к построению модели типа ARIMA:  
1. Остационарить ряд, установив порядок интеграции d;  
2. Исходя из поведения автокорреляционной и частной автокорреляционной функций установить параметры p и q;  
3. 

# Решение задачи

Потребуются некоторые библиотеки, скачиваем их с помощью pip3:

    sudo pip3 install numpy
    sudo pip3 install pandas
    sudo pip3 install matplotlib
    sudo pip3 install statsmodels
    sudo pip3 install sklearn
  
Для красоты и дополнительных баллов добавим seaborn
 
    sudo pip3 install seaborn
    
Заходим в директорию, содержащую файлы *testing.csv* , *training.csv* , task_2.ipynb.

    jupyter notebook task_2.ipynb

## Подзадача 1 

Считываем данные из *training.csv* , в котором хранится временной ряд. Указываем, что нужно различать 'Date' и 'Value', 
где столбец 'Date' - время :

> d_set = pd.read_csv('training.csv', index_col=['Date'], parse_dates=['Date'])

Визуализируем статистику, построенную по заданному ряду с помощью функции  
`def check_stationarity_graph(d_set)`

Отрисуем скользящие средние для разных размеров "окна" - год и 5 лет:

> dma_set_y = d_set.rolling(12).mean()

> dma_set_fy = d_set.rolling(60).mean()

Оценим стационарность ряда с помощью теста Дики-Фуллера `def check_stationarity_DF(dset)` :

> DF_test = smt.adfuller(dset.dropna())

Метод `dropna` возвращает объект, в котором нет значений ряда, если они не определены (NaN).

Также воспользуемся p-value, полученного при применении ДФ-теста. Предполагаем, что статистика и ряд независимые.
Тогда вероятность получить такие результаты = p-value. Это оценка нашей статистики.

## Подзадача 2

Разложим ряд в аддитивную модель:
> addit_m = sms.seasonal_decompose(d_set['Value'], model='additive')

Считаем, что наш ряд раскладывается в сумму трех рядов - тренда, сезональности и остатка.
Тренд получается нестационарным, а сезональность и остаток стационарными. 
Этот результат дает нам право работать с остатком: учить модель предсказывать по нему, а затем к получившемуся результату 
добавить ряды тренда и сезональности.

Теперь получим разложение в мультипликативную модель с помощью
> multi_m = sms.seasonal_decompose(d_set['Value'], model='multiplicative')

Здесь ряд данных представляется в виде произведения тренда, сезональности и остатка.
С помощью визуализации видим различия сезональности и остатка, 
но результаты стационарности сохраняются - можем работать аналогично.

## Подзадача 3

Определим порядок интегрированности ряда. Для этого сначала возьмем разности значений ряда с периодом = 1,
воспользуемся методом `diff` :
> d_set_diff = dset\['Value'\].diff(periods=k).dropna()

Проверив ДФ-тестом получившийся ряд, убедились в его стационарности  - по определению интегрированного ряда порядка 1, 
`d_set_diff` именно такого порядка. => Получили параметр d для модели ARIMA(p,d,q)

Для определения других параметров этой модели получим для `d_set_diff` графики автокорреляционной и частичной
автокорреляционной функций.
ACF экспоненциально затухает. PACF имеет выброс на лаге 1, для прочих лагов корреляции нет - оптимальная модель при 
p = 1, q = 0. (Что станет видно при сравнении графиков предсказаний)

Для сравнения построим различные модели ARIMA:

> model1 = sma.ARIMA(d_set, order=(1, 1, 1)).fit()

> model2 = sma.ARIMA(d_set, order=(1, 1, 0)).fit()

> model3 = sma.ARIMA(d_set, order=(1, 1, 2)).fit()

Для каждой модели построим предсказание методом `predict` с параметрами начала, конца и типа:

> pred3 = model3.predict('1989-01-01', '1993-12-01', typ='levels')

Графики предсказаний очень похожи, модель (1, 1, 0) чуть лучше.  


Показатели R^2  


Критерий Акаике


### Построение SARIMAX
